---
title: La storia della AI
date: 2023-01-10
updated: 2023-01-10
---
# La storia della AI

## La storia dell'apprendimento automatico

Per anni, noi, le persone, abbiamo cercato di dare un senso ai dati, elaborarli per ottenere approfondimenti e automatizzare questo processo il più possibile. Ed è per questo che è emersa la tecnologia che oggi chiamiamo "apprendimento automatico". Ora allacciati le cinture e intraprendiamo un intrigante viaggio nella storia dell'apprendimento automatico per scoprire come tutto è iniziato, come si è evoluto in quello che è oggi e cosa potrebbe riservare il futuro a questa tecnologia.

### 1642 – L'invenzione della vipera meccanica

Blaise Pascal ha creato una delle prime macchine addizionatrici meccaniche come tentativo di automatizzare l'elaborazione dei dati. Impiegava un meccanismo di ingranaggi e ruote, simile a quelli dei contachilometri e di altri dispositivi di conteggio.

Pascal è stato ispirato a costruire una calcolatrice per aiutare suo padre, il sovrintendente delle tasse a Rouen, con i lunghi calcoli aritmetici che doveva fare. Ha creato il dispositivo per aggiungere e sottrarre direttamente due numeri e moltiplicare e dividere.

![Contrariamente alla credenza popolare, la storia dell'apprendimento automatico, che consente alle macchine di apprendere compiti per i quali non sono specificatamente programmate](https://dataconomy.com/wp-content/uploads/2022/04/The-history-of-Machine-Learning-1.jpg "La storia del Machine Learning - risale al XVII secolo 1")

La storia dell'apprendimento automatico: _Ecco un sommatore meccanico o un calcolatore di base_

La calcolatrice aveva quadranti con ruote metalliche articolate con le cifre da 0 a 9 visualizzate attorno alla circonferenza di ciascuna ruota. L'utente ha inserito uno stilo nello spazio corrispondente tra i raggi e ha ruotato la manopola fino a raggiungere un fermo metallico nella parte inferiore per inserire una cifra, in modo simile a come funziona un quadrante rotante sul vecchio telefono. Il numero viene visualizzato nella finestra in alto a sinistra della calcolatrice. Quindi, ha semplicemente ricomposto il secondo numero da aggiungere, risultando nella visualizzazione del totale dell'accumulatore. Il meccanismo di trasporto, che aggiunge uno a nove su un quadrante e ne trasporta uno su quello successivo, era un'altra caratteristica di questa macchina.

### 1801 – L'invenzione del dispositivo di memorizzazione dei dati

Quando si guarda alla storia dell'apprendimento automatico, ci sono molte sorprese. Il nostro primo incontro è stato un dispositivo di archiviazione dati. Che ci crediate o no, il primo dispositivo di memorizzazione dei dati era, in effetti, un telaio per tessitura. Il primo utilizzo dell'archiviazione dei dati è stato in un telaio creato da un inventore francese di nome Joseph-Marie Jacquard, che utilizzava carte metalliche con fori per disporre i fili. Queste carte costituivano un programma per controllare il telaio e permettevano di ripetere una procedura con lo stesso esito ogni volta.

![La storia del Machine Learning - risale al XVII secolo](https://dataconomy.com/wp-content/uploads/2022/04/A-Jacquard-loom-showing-information-punchcards-National-Museum-of-Scotland.jpg "La storia del Machine Learning - risale al XVII secolo 2")

La storia del Machine Learning: _Un telaio Jacquard che mostra schede perforate informative, National Museum of Scotland
_

La macchina Jacquard utilizzava schede perforate intercambiabili per tessere il tessuto in qualsiasi motivo senza intervento umano. Le schede perforate furono usate da Charles Babbage, il famoso inventore inglese, come mezzo di input-output per il suo motore teorico e analitico e da Herman Hollerith per fornire dati alla sua macchina di censimento. Sono stati utilizzati anche per inserire dati in computer digitali, ma sono stati sostituiti da apparecchiature elettroniche.

### 1847 – L'introduzione della logica booleana

Nella logica booleana (nota anche come algebra booleana), tutti i valori sono veri o falsi. Questi valori true e false vengono utilizzati per verificare le condizioni su cui si basano la selezione e l'iterazione. Ecco come funzionano gli operatori booleani. George Boole ha creato gli operatori AND, OR e NOR utilizzando questa logica, rispondendo a domande su vero o falso, sì o no e 1 e 0 binari. Questi operatori sono ancora oggi utilizzati nelle ricerche web.

L'algebra booleana viene introdotta nell'intelligenza artificiale per affrontare alcuni dei problemi associati all'apprendimento automatico. Uno dei principali svantaggi di questa disciplina è che gli algoritmi di apprendimento automatico sono scatole nere, il che significa che non sappiamo molto su come operano autonomamente. Random forest e decision tree sono esempi di algoritmi di machine learning in grado di descrivere il funzionamento di un sistema, ma non sempre forniscono ottimi risultati. L'algebra booleana viene utilizzata per superare questa limitazione. L'algebra booleana è stata utilizzata nell'apprendimento automatico per produrre serie di regole comprensibili che possono ottenere prestazioni abbastanza buone.

### 1890 – La macchina di Hollerith si occupa di calcoli statistici

Herman Hollerith ha sviluppato il primo sistema combinato di calcolo meccanico e schede perforate per calcolare in modo efficiente le statistiche di milioni di individui. Era una macchina elettromeccanica costruita per aiutare a riassumere i dati memorizzati su schede perforate.

![Contrariamente alla credenza popolare, la storia dell'apprendimento automatico, che consente alle macchine di apprendere compiti per i quali non sono specificatamente programmate](https://dataconomy.com/wp-content/uploads/2022/04/The-history-of-Machine-Learning-2-scaled.jpg "La storia del Machine Learning - risale al XVII secolo 3")

La storia del machine learning: _I primi calcoli statistici sono stati fatti con macchine elettromeccaniche_

Il censimento del 1890 negli Stati Uniti ha richiesto otto anni per essere completato. Poiché la Costituzione richiede un censimento ogni dieci anni, era necessaria una forza lavoro più ampia per accelerare il processo. La tabulatrice è stata creata per facilitare l'elaborazione dei dati del censimento del 1890. Le versioni successive sono state ampiamente utilizzate nelle applicazioni di contabilità commerciale e gestione dell'inventario. Ha dato origine a una classe di macchine note come apparecchiature di registrazione delle unità e all'industria dell'elaborazione dei dati.

### 1943 – Viene presentato il primo modello matematico di un neurone biologico

L'articolo scientifico “[A Logical Calculus of the Ideas Immanent in Nervous Activity,](http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf)” pubblicato da Walter Pitts e Warren McCulloch, ha introdotto il primo modello matematico di reti neurali. Per molti, quel documento è stato il vero punto di partenza per la moderna disciplina del machine learning, che ha aperto la strada al deep learning e al machine learning quantistico.

L'articolo di McCulloch e Pitts del 1948 si basava su "[On Computable Numbers](https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf)" di Alan Turing per fornire un mezzo per descrivere le attività cerebrali in termini generali, dimostrando che i componenti di base collegati in una rete neurale potrebbero avere enormi capacità computazionali. Fino a quando le idee non furono applicate da John von Neuman, l'architetto dell'informatica moderna, Norbert Wiene e altri, il documento ricevette poca attenzione.

### 1949 – Hebb collega con successo il comportamento alle reti neurali e all'attività cerebrale

Nel 1949, lo psicologo canadese Donald O. Hebb, allora docente alla McGill University, pubblicò The Organization of Behavior: A Neuropsychological Theory. Questa è stata la prima volta che una regola di apprendimento fisiologico per il cambiamento sinaptico è stata resa esplicita sulla stampa ed è diventata nota come "sinapsi di Hebb".

![Contrariamente alla credenza popolare, la storia dell'apprendimento automatico, che consente alle macchine di apprendere compiti per i quali non sono specificatamente programmate](https://dataconomy.com/wp-content/uploads/2022/04/The-history-of-Machine-Learning-4.jpg "La storia del Machine Learning - risale al XVII secolo 4")

La storia dell'apprendimento automatico: _Le reti neurali sono oggi utilizzate in molti sistemi di intelligenza artificiale_

McCulloch e Pitts hanno sviluppato la teoria dell'assemblaggio cellulare nel loro articolo del 1951. Il modello di McCulloch e Pitts fu in seguito conosciuto come teoria di Hebbian, regola di Hebb, postulato di Hebb e teoria dell'assemblaggio cellulare. Si dice che i modelli che seguono questa idea mostrino "l'apprendimento hebbiano". Come affermato nel libro: "Quando un assone della cellula A è abbastanza vicino da eccitare la cellula B e partecipa ripetutamente o in modo persistente alla sua attivazione, in una o entrambe le cellule avviene un processo di crescita o un cambiamento metabolico tale che l'efficienza di A, come una delle cellule che sparano B, è aumentato.

> **_Il modello di Hebb ha aperto la strada allo sviluppo di macchine computazionali che replicano i processi neurologici naturali_**

Hebb si riferiva alla combinazione di neuroni che possono essere considerati come una singola unità di elaborazione come "assemblaggi di cellule". E il loro mix di connessioni ha determinato il cambiamento del cervello in risposta agli stimoli.

Il modello di Hebb per il funzionamento della mente ha avuto un'influenza significativa sul modo in cui gli psicologi considerano l'elaborazione dello stimolo in mente. Ha anche aperto la strada allo sviluppo di macchine computazionali che replicano i processi neurologici naturali, come l'apprendimento automatico. Mentre la trasmissione chimica è diventata la principale forma di trasmissione sinaptica nel sistema nervoso, le moderne reti neurali artificiali sono ancora costruite sulla base di segnali elettrici che viaggiano attraverso fili attorno ai quali è stata creata la teoria di Hebbian.

### 1950 – Turing trova un modo per misurare le capacità di pensiero delle macchine

**Il test di Turing** è un test di intelligenza artificiale per determinare se un computer pensa o meno come un essere umano. Il termine "Test di Turing" deriva da Alan Turing, informatico, crittoanalista, matematico e biologo teorico inglese che ha inventato il test.

È impossibile definire l'intelligenza in una macchina, secondo Turing. Se un computer può imitare le risposte umane in circostanze specifiche, si può dire che abbia un'intelligenza artificiale. Il test di Turing originale richiede tre terminali fisicamente separati l'uno dall'altro. Un terminale è controllato da un computer, mentre gli umani usano gli altri due.

![La storia del Machine Learning - risale al XVII secolo](https://dataconomy.com/wp-content/uploads/2022/04/history-of-machine-learning-1.jpg "La storia del Machine Learning Apprendimento - risale al XVII secolo 5")

La storia del Machine Learning: _La serie IBM 700 ha reso più semplici i calcoli scientifici e le operazioni commerciali, ma le macchine hanno anche fornito al mondo un po' di intrattenimento (Immagine per gentile concessione di IBM)_

Durante l'esperimento, uno degli umani funge da interrogante, con il secondo umano e il computer come intervistati. L'interrogante pone domande agli intervistati in una specifica area di studio all'interno di un formato e di un contesto specifici. Dopo una determinata durata o numero di domande, l'interrogante è invitato a selezionare quale rispondente era reale e quale artificiale. Il test viene eseguito numerose volte. Il computer è chiamato "intelligenza artificiale" se l'interrogante conferma il risultato corretto in metà o meno delle esecuzioni del test.

Il test prende il nome da Alan Turing, pioniere dell'apprendimento automatico negli anni '40 e '50. Nel 1950, Turing pubblicò un documento "Computing Machinery and Intelligence" per delineare il test.

### 1952 – In IBM viene sviluppato il primo programma di apprendimento informatico

Il programma Dama di Arthur Samuel, creato per giocare sull'IBM 701, fu mostrato al pubblico per la prima volta in televisione il 24 febbraio 1956. Robert Nealey, un maestro di dama autodefinito, giocò al gioco su un computer IBM 7094 nel 1962. Il computer ha vinto. Il programma Samuel Checkers ha perso altre partite contro Nealey. Tuttavia, era ancora considerato una pietra miliare per l'intelligenza artificiale e ha fornito al pubblico un esempio delle capacità di un computer elettronico nei primi anni '60.

Più il programma giocava, imparando quali mosse costituivano le strategie vincenti in una "modalità di apprendimento supervisionato" e incorporandole nel suo algoritmo, meglio si comportava al gioco.

Il programma di Samuel era una storia rivoluzionaria per l'epoca. I computer potrebbero battere la dama per la prima volta. Le creazioni elettroniche stavano sfidando il vantaggio intellettuale dell'umanità. Per il pubblico analfabeta della tecnologia del 1962, questo fu un evento significativo. Ha stabilito le basi affinché le macchine svolgano altri compiti intelligenti meglio degli umani. E la gente ha iniziato a pensare; i computer supereranno gli umani in intelligenza? Dopotutto, allora i computer esistevano solo da pochi anni e il campo dell'intelligenza artificiale era ancora agli inizi...

### 1958 – Viene progettato il Perceptron

Nel luglio 1958, l'Office of Naval Research degli Stati Uniti svelò un'invenzione straordinaria: la percezione. Un IBM 704, un computer da 5 tonnellate delle dimensioni di una stanza, è stato alimentato con una serie di schede perforate e, dopo 50 tentativi, ha imparato a identificare le schede con i segni a sinistra dai segni a destra.

Secondo il suo inventore, Frank Rosenblatt, era uno spettacolo del "perceptron", che era "la prima macchina in grado di generare un pensiero originale", secondo il suo inventore, Frank Rosenblatt.

“Le storie sulla creazione di macchine dotate di qualità umane sono state a lungo una provincia affascinante nel regno della fantascienza”, osservò Rosenblatt nel 1958. “Eppure stiamo per assistere alla nascita di una tale macchina – una macchina in grado di percepire, riconoscere , e identificare ciò che lo circonda senza alcun addestramento o controllo umano.

Aveva ragione sulla sua visione, ma ci sono voluti quasi mezzo decennio per fornirla.

### Gli anni '60: il tentativo dei Bell Labs di insegnare alle macchine a leggere

Il termine "deep learning" è stato ispirato da un rapporto della fine degli anni '60 che descriveva come gli scienziati dei Bell Labs stavano tentando di insegnare ai computer a leggere il testo inglese. L'invenzione dell'intelligenza artificiale, o "AI", nei primi anni '50 ha dato inizio alla tendenza verso quello che oggi è noto come machine learning.

### 1967 – Le macchine acquisiscono la capacità di riconoscere i modelli

È stato creato l'algoritmo del "vicino più vicino", che consente ai computer di eseguire il rilevamento di schemi rudimentali. Quando al programma veniva fornito un nuovo oggetto, lo confrontava con i dati esistenti e lo classificava come il vicino più prossimo, il che significava l'elemento più simile in memoria.

![Contrariamente alla credenza popolare, la storia dell'apprendimento automatico, che consente alle macchine di apprendere compiti per i quali non sono specificatamente programmate](https://dataconomy.com/wp-content/uploads/2022/04/The-history-of-Machine-Learning-3.jpg "La storia del Machine Learning - risale al XVII secolo 6")

La storia del machine learning: _Il riconoscimento dei pattern è alla base di molti sviluppi dell'IA raggiunti fino ad ora_

L'invenzione dell'algoritmo di riconoscimento dei modelli è attribuita a Fix e Hodges, che hanno dettagliato la loro tecnica non parametrica per la classificazione dei modelli nel 1951 in un numero non pubblicato di un rapporto della US Air Force School of Aviation Medicine. La regola k-nearest neighbor è stata inizialmente introdotta da Fix e Hodges come metodo non parametrico per la classificazione dei pattern.

### 1979 – A Stanford viene inventato uno dei primi veicoli autonomi

Lo Stanford Cart è stato uno sforzo decennale che si è evoluto in varie forme dal 1960 al 1980. È iniziato come uno studio di come sarebbe stato far funzionare un rover lunare dalla Terra e alla fine è stato rivitalizzato come veicolo autonomo. Da solo, il carrello dell'invenzione degli studenti potrebbe manovrare intorno agli ostacoli in una stanza. Lo Stanford Cart era inizialmente un robot mobile dotato di televisione telecomandata.

![La storia del Machine Learning - risale al XVII secolo](https://dataconomy.com/wp-content/uploads/2022/04/Stanford_Cart.jpg "La storia del Machine Learning - risale al XVII secolo 7")

È stato creato un programma per computer per controllare il carrello attraverso luoghi caotici, ottenendo tutte le sue informazioni sul mondo dalle immagini della TV a bordo. Il Carro ha utilizzato una varietà di stereopsi per scoprire le cose in tre dimensioni e determinare il proprio movimento. Sulla base di un modello creato con questi dati, ha pianificato un percorso che evita gli ostacoli verso la destinazione prescelta. Man mano che il Carro incontrava nuovi ostacoli nel suo viaggio, il piano si evolveva.

### 1981 - L'apprendimento basato sulla spiegazione richiede l'apprendimento supervisionato

Gerald Dejong ha aperto la strada all'apprendimento basato sulla spiegazione (EBL) in un articolo di giornale pubblicato nel 1981. L'EBL ha gettato le basi del moderno **apprendimento supervisionato** perché gli esempi di formazione integrano la conoscenza precedente del mondo. Il programma analizza i dati di addestramento ed elimina le informazioni non necessarie per creare una regola generale applicata alle istanze future. Ad esempio, se al software viene richiesto di concentrarsi sulla regina negli scacchi, scarterà tutti i pezzi senza effetto immediato.

### Anni '90: nascita di varie applicazioni di machine learning

Gli scienziati hanno iniziato ad applicare l'apprendimento automatico nel **data mining**, nel software adattivo, nelle applicazioni Web, nell'apprendimento del testo e nell'apprendimento delle lingue negli anni '90. Gli scienziati creano programmi per computer in grado di analizzare enormi quantità di dati e trarre conclusioni o imparare dai risultati. Il termine "Machine Learning" è stato coniato quando gli scienziati sono stati finalmente in grado di sviluppare software in modo tale che potesse apprendere e migliorare da solo, senza richiedere alcun input umano.

### Il Millennio – L'ascesa della programmazione adattiva

Il nuovo millennio ha visto un boom senza precedenti nella programmazione adattiva. L'apprendimento automatico è andato di pari passo con soluzioni adattive per molto tempo. Questi programmi possono identificare modelli, imparare dall'esperienza e migliorarsi in base al feedback che ricevono dall'ambiente.

Il deep learning è un esempio di programmazione adattiva, in cui gli algoritmi possono "vedere" e distinguere oggetti in immagini e video, che era la tecnologia alla base dei negozi Amazon GO. I clienti pagano quando escono senza dover fare la fila.

![amazon-go](https://dataconomy.com/wp-content/uploads/2022/04/amazon-go.jpg "La storia del Machine Learning - risale al XVII secolo 8")

La storia del Machine Learning: _I negozi Amazon GO fanno pagare i clienti quando escono senza fare la fila (Immagine per gentile concessione di Amazon)_

## 4 examples of human vs AI

Here are four examples of when artificial intelligence or computers bested some of the world’s brightest minds.

### 1979 - Backgammon: BKG 9.8 vs Luigi Villa 

The first time a computer competed against a world champion was in 1979, when the BKG 9.8 program authored by Hans J. Berliner defeated the world champion at the time, Tim Luigi Villa, by a substantial margin of 7-1.

### 1996 - Chess: IBM’s Deep Blue vs Garry Kasparov

In 1996, when Garry Kasparov faced IBM’s [Deep Blue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) in a best-of-13 series for the title of world chess champion, he was widely regarded as the greatest chess player ever. Even though Kasparov won the series with a score of 4-2; what’s remarkable is that the computer defeated him twice. After triumphing in the series, Kasparov remarked, “I could sense — I could smell — a new kind of intellect across the table.” A modified version of AI called ‘Deeper Blue’ bested Kasparov by forcing him to give up in Game 6 next year.

### 2010 - Go: DeepMind’S AlphaGO vs World’s Top Five Players 

Go is a game invented thousands of years ago in China and has evolved into one of the most complex and sophisticated games in the world. The Go community was devastated when DeepMind’s AlphaGo defeated Lee Sedol in four out of five matches. By defeating the next four best players on Earth, AlphaGo demonstrated to everyone that AI is superior to humans in the game.

### 2017 - Poker: Libratus vs Four Top Players 

In 2017, an AI dubbed the “Libratus” was able to defeat four professional poker players at the same time in a no-limit Texas Hold’ Em poker game. Poker is a highly psychological game in which one must interpret their opponent. An AI cannot determine whether someone is bluffing or not, yet two Carnegie Mellon computer scientists were able to beat everyone using an AI they created.
